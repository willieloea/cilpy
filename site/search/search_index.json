{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cilpy: A Computational Intelligence Library for Python","text":"<p><code>cilpy</code> is a Python library designed for experimenting with nature-inspired algorithms, with a special focus on dynamic and constrained optimization problems. Its modular design allows researchers and developers to easily benchmark existing algorithms or test new ones.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Modular Design: Problems, solvers, and experiment runners are decoupled, making it easy to mix and match components.</li> <li>Dynamic Problem Generators: Includes the well-known Moving Peaks Benchmark (MPB) and its constrained variant (CMPB) to create challenging dynamic landscapes.</li> <li>Rich Solver Collection: Provides a wide array of ready-to-use solvers, including variants of PSO, DE, and GAs.</li> <li>Experiment Runner: A simple utility to automate running experiments and logging results to CSV.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>TODO</p>"},{"location":"#project-structure","title":"Project Structure","text":"<ul> <li><code>/cilpy</code>: The core library source code.<ul> <li><code>/problem</code>: Contains problem generators.</li> <li><code>/solver</code>: Contains algorithm implementations.</li> <li><code>runner.py</code>: The experiment execution utility.</li> </ul> </li> <li><code>/examples</code>: Standalone scripts showing how to use the library.</li> <li><code>/test</code>: The testing suite for the library.</li> <li><code>/dev</code>: Contains resources for developers.</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the Contributing Guidelines for more details on how to set up your development environment, run tests, and submit changes.</p>"},{"location":"#license","title":"License","text":"<p>TODO</p>"},{"location":"#mkdocs-guide","title":"MkDocs guide","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>This file covers style, structure, documentation, and the process for adding new components to <code>cilpy</code>.</p>"},{"location":"contributing/#contributing-to-cilpy","title":"Contributing to <code>cilpy</code>","text":"<p>First off, thank you for considering contributing to <code>cilpy</code>! This project is designed to be a collaborative and extensible tool for the computational intelligence community. Your help is greatly appreciated.</p> <p>This document provides guidelines for contributing to the project. Following them helps maintain the quality and consistency of the codebase, making it easier for everyone to read, use, and contribute to.</p>"},{"location":"contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>How to Contribute</li> <li>Reporting Bugs</li> <li> <p>Suggesting Enhancements </p> </li> <li> <p>Coding Style and Conventions</p> </li> <li>General Style (PEP 8)</li> <li>Naming Conventions</li> <li>Type Hinting</li> <li>Docstrings</li> <li>Imports</li> <li>Core Dependencies</li> <li>Adding New Components</li> <li>Adding a New Solver</li> <li>Adding a New Problem</li> <li>Testing</li> <li>Contribution Process</li> </ul>"},{"location":"contributing/#how-to-contribute","title":"How to Contribute","text":""},{"location":"contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you find any bugs, contact the current maintainer, Willie Loftie-Eaton, through his email: willieloea@gmail.com</p>"},{"location":"contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>If you have an idea for a new feature or an improvement to an existing one, please contact the current maintainer, Willie Loftie-Eaton, through his email: willieloea@gmail.com</p>"},{"location":"contributing/#coding-style-and-conventions","title":"Coding Style and Conventions","text":"<p>Consistency is key. All Python code contributed to <code>cilpy</code> must follow these conventions.</p>"},{"location":"contributing/#general-style-pep-8","title":"General Style (PEP 8)","text":"<ul> <li>All code should adhere to PEP 8,  the official style guide for Python code.</li> <li>We recommend using a linter like <code>flake8</code> or an autoformatter like <code>black</code> to  automatically enforce these standards.</li> <li>Use a maximum line length of 79 characters for code.</li> <li>Use a maximum line length of 72 characters for docstrings and comments.</li> </ul>"},{"location":"contributing/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Modules: <code>snake_case</code> (e.g., <code>file_name.py</code>).</li> <li>Classes: <code>PascalCase</code> (e.g., <code>ClassName</code>).</li> <li>Functions &amp; Methods: <code>snake_case</code> (e.g., <code>function_name</code>).</li> <li>Variables: <code>snake_case</code> (e.g., <code>variable_name</code>).</li> <li>Constants: <code>ALL_CAPS</code> (e.g., <code>CONSTANT_CONST</code>).</li> <li>Internal Members: Use a single leading underscore <code>_</code> for internal  functions or methods that are not part of the public API (e.g.,  <code>_internal_function</code>).</li> </ul>"},{"location":"contributing/#type-hinting","title":"Type Hinting","text":"<ul> <li>Mandatory Type Hinting: All function and method signatures must  include type hints from the <code>typing</code> module. This is crucial for  maintainability and static analysis.</li> <li>Use the generic types defined in the interfaces where applicable (e.g.,  <code>Problem[SolutionType]</code>).</li> <li>See the <code>Problem</code> and <code>Solver</code> interfaces in <code>cilpy/problem/__init__.py</code> and  <code>cilpy/solver/__init__.py</code> for canonical examples.</li> </ul>"},{"location":"contributing/#docstrings","title":"Docstrings","text":"<ul> <li>All public modules, classes, functions, and methods must have a docstring.</li> <li>We use the Google-style docstring format. It is readable and can be  easily parsed by documentation generators.</li> <li>A good docstring explains what the code does, its parameters, and what it  returns.</li> </ul> <p>Example Google-style Docstring: <pre><code>def __init__(self,\n             problem: Problem[List[float]],\n             swarm_size: int = 30,\n             alpha_start: float = 1.0,\n             alpha_end: float = 0.5,\n             max_iterations: int = 1000):\n    \"\"\"Initializes the QPSO solver.\n\n    Args:\n        problem: The optimization problem to solve.\n        swarm_size: Number of particles in the swarm.\n        alpha_start: Initial value for the contraction-expansion coefficient.\n        alpha_end: Final value for the contraction-expansion coefficient.\n        max_iterations: The total number of iterations for the run. This is\n                        required to schedule the linear decrease of alpha.\n    \"\"\"\n    # ... implementation ...\n</code></pre></p>"},{"location":"contributing/#imports","title":"Imports","text":"<ul> <li>Imports should be grouped in the following order:<ol> <li>Standard library imports (e.g., <code>random</code>, <code>math</code>, <code>typing</code>).</li> <li>Third-party library imports (if any).</li> <li>Local application/library imports (e.g., <code>from ..problem import Problem</code>).</li> </ol> </li> <li>Within the <code>cilpy</code> library, use relative imports to refer to other parts of  the library (e.g., <code>from ..problem import Problem</code> inside a solver file).</li> </ul>"},{"location":"contributing/#core-dependencies","title":"Core Dependencies","text":"<p>For now, the library should have no dependencies. Contact Willie Loftie-Eaton through email (willieloea@gmail.com) if you think this should change.</p>"},{"location":"contributing/#adding-new-components","title":"Adding New Components","text":"<p>The library is designed for easy extension.</p>"},{"location":"contributing/#adding-a-new-solver","title":"Adding a New Solver","text":"<ol> <li>Create a new file in <code>cilpy/solver/</code> with a <code>snake_case</code> name (e.g., <code>my_new_solver.py</code>).</li> <li>Import the base <code>Solver</code> class: <code>from . import Solver</code>.</li> <li>Create your solver class, inheriting from <code>Solver</code>. Specify the <code>SolutionType</code> you are working with (e.g., <code>class MyNewSolver(Solver[List[float]]):</code>).</li> <li>Implement the required abstract methods: <code>__init__</code>, <code>step</code>, and <code>get_best</code>.</li> <li>Your <code>__init__</code> method must call <code>super().__init__(problem, **kwargs)</code>.</li> <li>Follow all coding style and documentation guidelines mentioned above.</li> <li>Add your new solver to <code>cilpy/solver/__init__.py</code> to make it easily importable.</li> </ol>"},{"location":"contributing/#adding-a-new-problem","title":"Adding a New Problem","text":"<ol> <li>Create a new file in <code>cilpy/problem/</code> (e.g., <code>my_new_problem.py</code>).</li> <li>Import the base <code>Problem</code> class: <code>from . import Problem</code>.</li> <li>Create your problem class, inheriting from <code>Problem</code>.</li> <li>Implement all required abstract methods and properties from the <code>Problem</code> interface.</li> <li>Add your new problem to <code>cilpy/problem/__init__.py</code>.</li> </ol>"},{"location":"contributing/#testing","title":"Testing","text":"<ul> <li>The <code>test/</code> directory contains tests for the library.</li> <li>When you add a new feature or fix a bug, you must add corresponding tests.</li> <li>Tests should be self-contained and not require manual intervention.</li> <li>We aim to use the <code>pytest</code> framework for testing.</li> </ul>"},{"location":"contributing/#contribution-process","title":"Contribution Process","text":"<ol> <li>Ensure your code lints without errors and follows the style guide.</li> <li>Make sure you have added or updated tests for your changes.</li> <li>Update the relevant documentation (docstrings, READMEs) if you have changed any public APIs.</li> <li>Your contribution should have a clear, descriptive title (e.g., \"Feature: Add GVPSO Solver\", \"Fix: Off-by-one error in runner\").</li> <li>As part of you contribution, provide a description explaining the \"what\" and \"why\" of your changes.</li> </ol> <p>Thank you again for your contribution</p>"},{"location":"api/problem/","title":"Problem API Reference","text":"<p>This section provides the auto-generated API documentation for problem generators in <code>cilpy</code>.</p>"},{"location":"api/problem/#problem-interface","title":"Problem Interface","text":""},{"location":"api/problem/#cilpy.problem.Problem","title":"<code>cilpy.problem.Problem</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[SolutionType]</code></p> <p>An abstract interface for optimization problems in cilpy.</p> <p>All problems in <code>cilpy.problem</code> should implement this interface to ensure compatibility with solvers and comparison tools. The interface is generic to support different solution representations (e.g., List[float], List[int], custom objects).</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>class Problem(ABC, Generic[SolutionType]):\n    \"\"\"\n    An abstract interface for optimization problems in cilpy.\n\n    All problems in `cilpy.problem` should implement this interface to ensure\n    compatibility with solvers and comparison tools. The interface is generic\n    to support different solution representations (e.g., List[float], List[int],\n    custom objects).\n    \"\"\"\n\n    @abstractmethod\n    def get_objective_functions(self) -&gt; List[Callable[[SolutionType], float]]:\n        \"\"\"\n        Returns the objective function(s) of a problem.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_constraint_functions(self) -&gt; Tuple[List[Callable], List[Callable]]:\n        \"\"\"\n        Returns the constraint functions of a problem.\n\n        Returns:\n            Tuple[List[Callable], List[Callable]]: A tuple containing:\n                - List of inequality constraints\n                - List of equality constraints\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_bounds(self) -&gt; Any:\n        \"\"\"\n        Returns the search space boundaries or constraints for the problem.\n\n        Returns:\n            Any: The bounds or constraints defining the solution space (e.g.,\n            Tuple[List[float], List[float]] for real-valued problems, or other\n            structures for different solution types).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_dimension(self) -&gt; int:\n        \"\"\"\n        Returns the dimensionality or size of the solution space.\n\n        Returns:\n            int: The number of dimensions in a solution\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def is_dynamic(self) -&gt; Tuple[bool, bool]:\n        \"\"\"\n        Indicates whether the problem has dynamic objectives or constraints.\n\n        Returns:\n            Tuple[bool, bool]: A tuple of (is_objective_dynamic,\n                               is_constraint_dynamic).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def change_environment(self, iteration: int) -&gt; None:\n        \"\"\"\n        Updates the problem state for dynamic problems (e.g., change constraints\n        or objectives).\n\n        Args:\n            iteration (int): The current iteration/generation of the solver.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def initialize_solution(self) -&gt; SolutionType:\n        \"\"\"\n        Generates or defines the structure of an initial solution for the\n        problem.\n\n        Returns:\n            SolutionType: An initial solution (e.g., a random List[float],\n                          List[int], or custom object).\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def is_multiobjective(self) -&gt; bool:\n        \"\"\"\n        Indicates whether the problem is a multi-objective optimization problem.\n\n        Returns:\n            bool: True if the problem is a MOOP, False otherwise\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -&gt; str:\n        \"\"\"\n        Returns the name or identifier of the problem.\n\n        Returns:\n            str: A string identifier for the problem.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.is_multiobjective","title":"<code>is_multiobjective</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Indicates whether the problem is a multi-objective optimization problem.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the problem is a MOOP, False otherwise</p>"},{"location":"api/problem/#cilpy.problem.Problem.name","title":"<code>name</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Returns the name or identifier of the problem.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string identifier for the problem.</p>"},{"location":"api/problem/#cilpy.problem.Problem.change_environment","title":"<code>change_environment(iteration)</code>  <code>abstractmethod</code>","text":"<p>Updates the problem state for dynamic problems (e.g., change constraints or objectives).</p> <p>Parameters:</p> Name Type Description Default <code>iteration</code> <code>int</code> <p>The current iteration/generation of the solver.</p> required Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef change_environment(self, iteration: int) -&gt; None:\n    \"\"\"\n    Updates the problem state for dynamic problems (e.g., change constraints\n    or objectives).\n\n    Args:\n        iteration (int): The current iteration/generation of the solver.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.get_bounds","title":"<code>get_bounds()</code>  <code>abstractmethod</code>","text":"<p>Returns the search space boundaries or constraints for the problem.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The bounds or constraints defining the solution space (e.g.,</p> <code>Any</code> <p>Tuple[List[float], List[float]] for real-valued problems, or other</p> <code>Any</code> <p>structures for different solution types).</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef get_bounds(self) -&gt; Any:\n    \"\"\"\n    Returns the search space boundaries or constraints for the problem.\n\n    Returns:\n        Any: The bounds or constraints defining the solution space (e.g.,\n        Tuple[List[float], List[float]] for real-valued problems, or other\n        structures for different solution types).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.get_constraint_functions","title":"<code>get_constraint_functions()</code>  <code>abstractmethod</code>","text":"<p>Returns the constraint functions of a problem.</p> <p>Returns:</p> Type Description <code>Tuple[List[Callable], List[Callable]]</code> <p>Tuple[List[Callable], List[Callable]]: A tuple containing: - List of inequality constraints - List of equality constraints</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef get_constraint_functions(self) -&gt; Tuple[List[Callable], List[Callable]]:\n    \"\"\"\n    Returns the constraint functions of a problem.\n\n    Returns:\n        Tuple[List[Callable], List[Callable]]: A tuple containing:\n            - List of inequality constraints\n            - List of equality constraints\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.get_dimension","title":"<code>get_dimension()</code>  <code>abstractmethod</code>","text":"<p>Returns the dimensionality or size of the solution space.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The number of dimensions in a solution</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef get_dimension(self) -&gt; int:\n    \"\"\"\n    Returns the dimensionality or size of the solution space.\n\n    Returns:\n        int: The number of dimensions in a solution\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.get_objective_functions","title":"<code>get_objective_functions()</code>  <code>abstractmethod</code>","text":"<p>Returns the objective function(s) of a problem.</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef get_objective_functions(self) -&gt; List[Callable[[SolutionType], float]]:\n    \"\"\"\n    Returns the objective function(s) of a problem.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.initialize_solution","title":"<code>initialize_solution()</code>  <code>abstractmethod</code>","text":"<p>Generates or defines the structure of an initial solution for the problem.</p> <p>Returns:</p> Name Type Description <code>SolutionType</code> <code>SolutionType</code> <p>An initial solution (e.g., a random List[float],           List[int], or custom object).</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef initialize_solution(self) -&gt; SolutionType:\n    \"\"\"\n    Generates or defines the structure of an initial solution for the\n    problem.\n\n    Returns:\n        SolutionType: An initial solution (e.g., a random List[float],\n                      List[int], or custom object).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#cilpy.problem.Problem.is_dynamic","title":"<code>is_dynamic()</code>  <code>abstractmethod</code>","text":"<p>Indicates whether the problem has dynamic objectives or constraints.</p> <p>Returns:</p> Type Description <code>Tuple[bool, bool]</code> <p>Tuple[bool, bool]: A tuple of (is_objective_dynamic,                is_constraint_dynamic).</p> Source code in <code>cilpy/problem/__init__.py</code> <pre><code>@abstractmethod\ndef is_dynamic(self) -&gt; Tuple[bool, bool]:\n    \"\"\"\n    Indicates whether the problem has dynamic objectives or constraints.\n\n    Returns:\n        Tuple[bool, bool]: A tuple of (is_objective_dynamic,\n                           is_constraint_dynamic).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/problem/#movingpeaksbenchmark","title":"MovingPeaksBenchmark","text":""},{"location":"api/problem/#cilpy.problem.mpb.MovingPeaksBenchmark","title":"<code>cilpy.problem.mpb.MovingPeaksBenchmark</code>","text":"<p>               Bases: <code>Problem[List[float]]</code></p> <p>An implementation of the Moving Peaks Benchmark (MPB) generator.</p> <p>This class generates a dynamic optimization problem landscape consisting of several cone-shaped peaks that can change height, width, and position over time. It adheres to the <code>cilpy.problem.Problem</code> interface.</p> References <p>Branke, J. (2001). \"Evolutionary Optimization in Dynamic Environments\".</p> Source code in <code>cilpy/problem/mpb.py</code> <pre><code>class MovingPeaksBenchmark(Problem[List[float]]):\n    \"\"\"\n    An implementation of the Moving Peaks Benchmark (MPB) generator.\n\n    This class generates a dynamic optimization problem landscape consisting of\n    several cone-shaped peaks that can change height, width, and position over\n    time. It adheres to the `cilpy.problem.Problem` interface.\n\n    References:\n        Branke, J. (2001). \"Evolutionary Optimization in Dynamic Environments\".\n    \"\"\"\n\n    def __init__(\n        self,\n        num_peaks: int = 10,\n        dimension: int = 2,\n        min_coord: float = 0.0,\n        max_coord: float = 100.0,\n        min_height: float = 30.0,\n        max_height: float = 70.0,\n        min_width: float = 1.0,\n        max_width: float = 12.0,\n        change_frequency: int = 500,\n        change_severity: float = 1.0,\n        height_severity: float = 7.0,\n        width_severity: float = 1.0,\n        lambda_param: float = 0.0,\n        problem_name: str = \"MovingPeaksBenchmark\",\n    ):\n        \"\"\"\n        Initializes the Moving Peaks Benchmark generator.\n\n        Args:\n            num_peaks: Number of peaks in the landscape.\n            dimension: Dimensionality of the search space.\n            min_coord: Lower bound for each dimension of the search space.\n            max_coord: Upper bound for each dimension of the search space.\n            min_height: Lower bound for the initial height of peaks.\n            max_height: Upper bound for the initial height of peaks.\n            min_width: Lower bound for the initial width of peaks.\n            max_width: Upper bound for the initial width of peaks.\n            change_frequency: Number of fitness evaluations between environment\n                              changes.\n            change_severity: The severity of peak movement.\n            height_severity: The severity of peak height changes.\n            width_severity: The severity of peak width changes.\n            lambda_param: Correlation coefficient for peak movement. 0.0 for\n                          random, 1.0 for linear movement.\n            problem_name: A name for the problem instance.\n        \"\"\"\n        self._dimension = dimension\n        self._bounds = (min_coord, max_coord)\n        self._name = problem_name\n        self._change_frequency = change_frequency\n\n        # Severity parameters for updates\n        self._change_sev = change_severity\n        self._height_sev = height_severity\n        self._width_sev = width_severity\n        self._lambda = lambda_param\n\n        # Initialize peaks\n        self.peaks: List[_Peak] = []\n        for _ in range(num_peaks):\n            pos = [random.uniform(min_coord, max_coord) for _ in range(dimension)]\n            height = random.uniform(min_height, max_height)\n            width = random.uniform(min_width, max_width)\n            self.peaks.append(_Peak(pos, height, width))\n\n        # Base landscape value B\n        self.base_value = 0.0\n\n    def _get_raw_maximization_value(self, x: List[float]) -&gt; float:\n        \"\"\"\n        Calculates the raw fitness of a solution x.\n        This is the true maximization value of the landscape.\n        F(x, t) = max{B, p_0(x, e_0), ..., p_n(x, e_n)}\n        \"\"\"\n        peak_values = [p.evaluate(x) for p in self.peaks]\n        return max([self.base_value] + peak_values)\n\n    def _fitness(self, x: List[float]) -&gt; float:\n        \"\"\"\n        Calculates the fitness for a minimization solver by negating the\n        raw maximization value.\n        \"\"\"\n        return -self._get_raw_maximization_value(x)\n\n    def get_objective_functions(self) -&gt; List[Callable[[List[float]], float]]:\n        return [self._fitness]\n\n    def get_constraint_functions(self) -&gt; Tuple[List[Callable], List[Callable]]:\n        return ([], [])  # MPB is unconstrained\n\n    def get_bounds(self) -&gt; Tuple[List[float], List[float]]:\n        min_b, max_b = self._bounds\n        return ([min_b] * self._dimension, [max_b] * self._dimension)\n\n    def get_dimension(self) -&gt; int:\n        return self._dimension\n\n    def is_dynamic(self) -&gt; Tuple[bool, bool]:\n        return (True, False)  # Dynamic objective, static constraints\n\n    def change_environment(self, iteration: int) -&gt; None:\n        \"\"\"\n        Updates the peak landscape if the change frequency is met.\n        \"\"\"\n        if self._change_frequency &gt; 0 and iteration % self._change_frequency == 0:\n            for peak in self.peaks:\n                peak.update(\n                    height_sev=self._height_sev,\n                    width_sev=self._width_sev,\n                    change_sev=self._change_sev,\n                    lambda_param=self._lambda,\n                    bounds=self._bounds,\n                    dim=self._dimension,\n                )\n\n    def initialize_solution(self) -&gt; List[float]:\n        min_b, max_b = self._bounds\n        return [random.uniform(min_b, max_b) for _ in range(self._dimension)]\n\n    @property\n    def is_multiobjective(self) -&gt; bool:\n        return False\n\n    @property\n    def name(self) -&gt; str:\n        return self._name\n</code></pre>"},{"location":"api/problem/#cilpy.problem.mpb.MovingPeaksBenchmark.__init__","title":"<code>__init__(num_peaks=10, dimension=2, min_coord=0.0, max_coord=100.0, min_height=30.0, max_height=70.0, min_width=1.0, max_width=12.0, change_frequency=500, change_severity=1.0, height_severity=7.0, width_severity=1.0, lambda_param=0.0, problem_name='MovingPeaksBenchmark')</code>","text":"<p>Initializes the Moving Peaks Benchmark generator.</p> <p>Parameters:</p> Name Type Description Default <code>num_peaks</code> <code>int</code> <p>Number of peaks in the landscape.</p> <code>10</code> <code>dimension</code> <code>int</code> <p>Dimensionality of the search space.</p> <code>2</code> <code>min_coord</code> <code>float</code> <p>Lower bound for each dimension of the search space.</p> <code>0.0</code> <code>max_coord</code> <code>float</code> <p>Upper bound for each dimension of the search space.</p> <code>100.0</code> <code>min_height</code> <code>float</code> <p>Lower bound for the initial height of peaks.</p> <code>30.0</code> <code>max_height</code> <code>float</code> <p>Upper bound for the initial height of peaks.</p> <code>70.0</code> <code>min_width</code> <code>float</code> <p>Lower bound for the initial width of peaks.</p> <code>1.0</code> <code>max_width</code> <code>float</code> <p>Upper bound for the initial width of peaks.</p> <code>12.0</code> <code>change_frequency</code> <code>int</code> <p>Number of fitness evaluations between environment               changes.</p> <code>500</code> <code>change_severity</code> <code>float</code> <p>The severity of peak movement.</p> <code>1.0</code> <code>height_severity</code> <code>float</code> <p>The severity of peak height changes.</p> <code>7.0</code> <code>width_severity</code> <code>float</code> <p>The severity of peak width changes.</p> <code>1.0</code> <code>lambda_param</code> <code>float</code> <p>Correlation coefficient for peak movement. 0.0 for           random, 1.0 for linear movement.</p> <code>0.0</code> <code>problem_name</code> <code>str</code> <p>A name for the problem instance.</p> <code>'MovingPeaksBenchmark'</code> Source code in <code>cilpy/problem/mpb.py</code> <pre><code>def __init__(\n    self,\n    num_peaks: int = 10,\n    dimension: int = 2,\n    min_coord: float = 0.0,\n    max_coord: float = 100.0,\n    min_height: float = 30.0,\n    max_height: float = 70.0,\n    min_width: float = 1.0,\n    max_width: float = 12.0,\n    change_frequency: int = 500,\n    change_severity: float = 1.0,\n    height_severity: float = 7.0,\n    width_severity: float = 1.0,\n    lambda_param: float = 0.0,\n    problem_name: str = \"MovingPeaksBenchmark\",\n):\n    \"\"\"\n    Initializes the Moving Peaks Benchmark generator.\n\n    Args:\n        num_peaks: Number of peaks in the landscape.\n        dimension: Dimensionality of the search space.\n        min_coord: Lower bound for each dimension of the search space.\n        max_coord: Upper bound for each dimension of the search space.\n        min_height: Lower bound for the initial height of peaks.\n        max_height: Upper bound for the initial height of peaks.\n        min_width: Lower bound for the initial width of peaks.\n        max_width: Upper bound for the initial width of peaks.\n        change_frequency: Number of fitness evaluations between environment\n                          changes.\n        change_severity: The severity of peak movement.\n        height_severity: The severity of peak height changes.\n        width_severity: The severity of peak width changes.\n        lambda_param: Correlation coefficient for peak movement. 0.0 for\n                      random, 1.0 for linear movement.\n        problem_name: A name for the problem instance.\n    \"\"\"\n    self._dimension = dimension\n    self._bounds = (min_coord, max_coord)\n    self._name = problem_name\n    self._change_frequency = change_frequency\n\n    # Severity parameters for updates\n    self._change_sev = change_severity\n    self._height_sev = height_severity\n    self._width_sev = width_severity\n    self._lambda = lambda_param\n\n    # Initialize peaks\n    self.peaks: List[_Peak] = []\n    for _ in range(num_peaks):\n        pos = [random.uniform(min_coord, max_coord) for _ in range(dimension)]\n        height = random.uniform(min_height, max_height)\n        width = random.uniform(min_width, max_width)\n        self.peaks.append(_Peak(pos, height, width))\n\n    # Base landscape value B\n    self.base_value = 0.0\n</code></pre>"},{"location":"api/problem/#cilpy.problem.mpb.MovingPeaksBenchmark.change_environment","title":"<code>change_environment(iteration)</code>","text":"<p>Updates the peak landscape if the change frequency is met.</p> Source code in <code>cilpy/problem/mpb.py</code> <pre><code>def change_environment(self, iteration: int) -&gt; None:\n    \"\"\"\n    Updates the peak landscape if the change frequency is met.\n    \"\"\"\n    if self._change_frequency &gt; 0 and iteration % self._change_frequency == 0:\n        for peak in self.peaks:\n            peak.update(\n                height_sev=self._height_sev,\n                width_sev=self._width_sev,\n                change_sev=self._change_sev,\n                lambda_param=self._lambda,\n                bounds=self._bounds,\n                dim=self._dimension,\n            )\n</code></pre>"},{"location":"api/problem/#constrainedmovingpeaksbenchmark","title":"ConstrainedMovingPeaksBenchmark","text":""},{"location":"api/problem/#cilpy.problem.cmpb.ConstrainedMovingPeaksBenchmark","title":"<code>cilpy.problem.cmpb.ConstrainedMovingPeaksBenchmark</code>","text":"<p>               Bases: <code>Problem[List[float]]</code></p> <p>An implementation of the Constrained Moving Peaks Benchmark (CMPB).</p> <p>This class generates a dynamic constrained optimization problem by composing two independent Moving Peaks Benchmark instances: one for the objective function (f) and one for the constraint landscape (g).</p> <p>The final optimization problem is to maximize h(x) = f(x) - g(x), subject to the constraint h(x) &gt;= 0 (i.e., f(x) &gt;= g(x)).</p> <p>For standard minimization solvers, the problem is formulated as: Minimize -h(x) = g(x) - f(x) Subject to the inequality constraint: g(x) - f(x) &lt;= 0.</p> References <p>Pampar\u00e0, P. (2021). \"Dynamic Co-Evolutionary Algorithms for Dynamic, Constrained Optimisation Problems\". Chapter 5.</p> Source code in <code>cilpy/problem/cmpb.py</code> <pre><code>class ConstrainedMovingPeaksBenchmark(Problem[List[float]]):\n    \"\"\"\n    An implementation of the Constrained Moving Peaks Benchmark (CMPB).\n\n    This class generates a dynamic constrained optimization problem by composing\n    two independent Moving Peaks Benchmark instances: one for the objective\n    function (f) and one for the constraint landscape (g).\n\n    The final optimization problem is to maximize h(x) = f(x) - g(x),\n    subject to the constraint h(x) &gt;= 0 (i.e., f(x) &gt;= g(x)).\n\n    For standard minimization solvers, the problem is formulated as:\n    Minimize -h(x) = g(x) - f(x)\n    Subject to the inequality constraint: g(x) - f(x) &lt;= 0.\n\n    References:\n        Pampar\u00e0, P. (2021). \"Dynamic Co-Evolutionary Algorithms for Dynamic,\n        Constrained Optimisation Problems\". Chapter 5.\n    \"\"\"\n\n    def __init__(\n        self,\n        f_params: Dict[str, Any],\n        g_params: Dict[str, Any],\n        problem_name: str = \"ConstrainedMovingPeaksBenchmark\",\n    ):\n        \"\"\"\n        Initializes the Constrained Moving Peaks Benchmark generator.\n\n        Args:\n            f_params: A dictionary of parameters for the objective landscape\n                      (f), to be passed to the MovingPeaksBenchmark constructor.\n            g_params: A dictionary of parameters for the constraint landscape\n                      (g), to be passed to the MovingPeaksBenchmark constructor.\n            problem_name: A name for the problem instance.\n        \"\"\"\n        if f_params.get(\"dimension\") != g_params.get(\"dimension\"):\n            raise ValueError(\n                \"The dimensions of the objective (f) and constraint (g) \"\n                \"landscapes must be the same.\"\n            )\n\n        self.f_landscape = MovingPeaksBenchmark(**f_params)\n        self.g_landscape = MovingPeaksBenchmark(**g_params)\n\n        # The bounds are determined by the objective function landscape `f`\n        self._bounds = self.f_landscape.get_bounds()\n        self._name = problem_name\n        self._dimension = self.f_landscape.get_dimension()\n        self._is_objective_dynamic = self.f_landscape._change_frequency &gt; 0\n        self._is_constraint_dynamic = self.g_landscape._change_frequency &gt; 0\n\n    def _h_fitness(self, x: List[float]) -&gt; float:\n        \"\"\"\n        The composed objective function, h(x) = f(x) - g(x).\n        \"\"\"\n        f_val = self.f_landscape._get_raw_maximization_value(x)\n        g_val = self.g_landscape._get_raw_maximization_value(x)\n        h_val = f_val - g_val\n        return -h_val  # Return negative for minimization\n\n    def _constraint(self, x: List[float]) -&gt; float:\n        \"\"\"\n        The inequality constraint function, g(x) - f(x) &lt;= 0.\n        A solution is feasible if the return value is &lt;= 0.\n        \"\"\"\n        f_val = self.f_landscape._get_raw_maximization_value(x)\n        g_val = self.g_landscape._get_raw_maximization_value(x)\n        return g_val - f_val\n\n    def get_objective_functions(self) -&gt; List[Callable[[List[float]], float]]:\n        return [self._h_fitness]\n\n    def get_constraint_functions(self) -&gt; Tuple[List[Callable], List[Callable]]:\n        # One inequality constraint, no equality constraints\n        return ([self._constraint], [])\n\n    def get_bounds(self) -&gt; Tuple[List[float], List[float]]:\n        return self._bounds\n\n    def get_dimension(self) -&gt; int:\n        return self._dimension\n\n    def is_dynamic(self) -&gt; Tuple[bool, bool]:\n        return (self._is_objective_dynamic, self._is_constraint_dynamic)\n\n    def change_environment(self, iteration: int) -&gt; None:\n        \"\"\"\n        Updates both the objective and constraint landscapes.\n        \"\"\"\n        self.f_landscape.change_environment(iteration)\n        self.g_landscape.change_environment(iteration)\n\n    def initialize_solution(self) -&gt; List[float]:\n        \"\"\"\n        Generates an initial solution within the bounds of the objective 'f'\n        landscape.\n        \"\"\"\n        return self.f_landscape.initialize_solution()\n\n    @property\n    def is_multiobjective(self) -&gt; bool:\n        return False\n\n    @property\n    def name(self) -&gt; str:\n        return self._name\n</code></pre>"},{"location":"api/problem/#cilpy.problem.cmpb.ConstrainedMovingPeaksBenchmark.__init__","title":"<code>__init__(f_params, g_params, problem_name='ConstrainedMovingPeaksBenchmark')</code>","text":"<p>Initializes the Constrained Moving Peaks Benchmark generator.</p> <p>Parameters:</p> Name Type Description Default <code>f_params</code> <code>Dict[str, Any]</code> <p>A dictionary of parameters for the objective landscape       (f), to be passed to the MovingPeaksBenchmark constructor.</p> required <code>g_params</code> <code>Dict[str, Any]</code> <p>A dictionary of parameters for the constraint landscape       (g), to be passed to the MovingPeaksBenchmark constructor.</p> required <code>problem_name</code> <code>str</code> <p>A name for the problem instance.</p> <code>'ConstrainedMovingPeaksBenchmark'</code> Source code in <code>cilpy/problem/cmpb.py</code> <pre><code>def __init__(\n    self,\n    f_params: Dict[str, Any],\n    g_params: Dict[str, Any],\n    problem_name: str = \"ConstrainedMovingPeaksBenchmark\",\n):\n    \"\"\"\n    Initializes the Constrained Moving Peaks Benchmark generator.\n\n    Args:\n        f_params: A dictionary of parameters for the objective landscape\n                  (f), to be passed to the MovingPeaksBenchmark constructor.\n        g_params: A dictionary of parameters for the constraint landscape\n                  (g), to be passed to the MovingPeaksBenchmark constructor.\n        problem_name: A name for the problem instance.\n    \"\"\"\n    if f_params.get(\"dimension\") != g_params.get(\"dimension\"):\n        raise ValueError(\n            \"The dimensions of the objective (f) and constraint (g) \"\n            \"landscapes must be the same.\"\n        )\n\n    self.f_landscape = MovingPeaksBenchmark(**f_params)\n    self.g_landscape = MovingPeaksBenchmark(**g_params)\n\n    # The bounds are determined by the objective function landscape `f`\n    self._bounds = self.f_landscape.get_bounds()\n    self._name = problem_name\n    self._dimension = self.f_landscape.get_dimension()\n    self._is_objective_dynamic = self.f_landscape._change_frequency &gt; 0\n    self._is_constraint_dynamic = self.g_landscape._change_frequency &gt; 0\n</code></pre>"},{"location":"api/problem/#cilpy.problem.cmpb.ConstrainedMovingPeaksBenchmark.change_environment","title":"<code>change_environment(iteration)</code>","text":"<p>Updates both the objective and constraint landscapes.</p> Source code in <code>cilpy/problem/cmpb.py</code> <pre><code>def change_environment(self, iteration: int) -&gt; None:\n    \"\"\"\n    Updates both the objective and constraint landscapes.\n    \"\"\"\n    self.f_landscape.change_environment(iteration)\n    self.g_landscape.change_environment(iteration)\n</code></pre>"},{"location":"api/problem/#cilpy.problem.cmpb.ConstrainedMovingPeaksBenchmark.initialize_solution","title":"<code>initialize_solution()</code>","text":"<p>Generates an initial solution within the bounds of the objective 'f' landscape.</p> Source code in <code>cilpy/problem/cmpb.py</code> <pre><code>def initialize_solution(self) -&gt; List[float]:\n    \"\"\"\n    Generates an initial solution within the bounds of the objective 'f'\n    landscape.\n    \"\"\"\n    return self.f_landscape.initialize_solution()\n</code></pre>"},{"location":"api/problem/#sphere","title":"Sphere","text":""},{"location":"api/problem/#cilpy.problem.sphere.Sphere","title":"<code>cilpy.problem.sphere.Sphere</code>","text":"<p>               Bases: <code>Problem[List[float]]</code></p> Source code in <code>cilpy/problem/sphere.py</code> <pre><code>class Sphere(Problem[List[float]]):\n    def __init__(self, dimension: int = 2):\n        self._dimension = dimension\n        self._bounds = ([-10.0] * dimension, [10.0] * dimension)\n        self._name = \"Sphere\"\n        self._change_frequency = 0\n\n    def get_objective_functions(self) -&gt; List[Callable[[List[float]], float]]:\n        def objective(x: List[float]) -&gt; float:\n            return sum(x_i * x_i for x_i in x)\n\n        return [objective]\n\n    def get_constraint_functions(self) -&gt; Tuple[List[Callable], List[Callable]]:\n        return [], []\n\n    def get_bounds(self) -&gt; Tuple[List[float], List[float]]:\n        return self._bounds\n\n    def get_dimension(self) -&gt; int:\n        return self._dimension\n\n    def is_dynamic(self) -&gt; Tuple[bool, bool]:\n        return (False, False)\n\n    def change_environment(self, iteration: int) -&gt; None:\n        pass\n\n    def initialize_solution(self) -&gt; List[float]:\n        lower, upper = self._bounds\n        return [random.uniform(l, u) for l, u in zip(lower, upper)]\n\n    @property\n    def is_multiobjective(self) -&gt; bool:\n        return False\n\n    @property\n    def name(self) -&gt; str:\n        return self._name\n</code></pre>"},{"location":"api/solver/","title":"Solver API Reference","text":"<p>This section provides the auto-generated API documentation for solvers in <code>cilpy</code>.</p>"},{"location":"api/solver/#solver-interface","title":"Solver Interface","text":""},{"location":"api/solver/#cilpy.solver.Solver","title":"<code>cilpy.solver.Solver</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[SolutionType]</code></p> <p>An abstract interface for a problem solver.</p> <p>All solvers in <code>cilpy.solver</code> should implement this interface. The interface is generic to support different solution representations (e.g., List[float], List[int], custom objects).</p> Source code in <code>cilpy/solver/__init__.py</code> <pre><code>class Solver(ABC, Generic[SolutionType]):\n    \"\"\"\n    An abstract interface for a problem solver.\n\n    All solvers in `cilpy.solver` should implement this interface. The interface\n    is generic to support different solution representations (e.g., List[float],\n    List[int], custom objects).\n    \"\"\"\n\n    def __init__(self, problem: Problem[SolutionType], **kwargs):\n        \"\"\"\n        Initializes the solver with a given problem and algorithm-specific\n        parameters.\n\n        Args:\n            problem (Problem[SolutionType]): The optimization problem to solve.\n            **kwargs: Algorithm-specific parameters.\n        \"\"\"\n        self.problem = problem\n\n    @abstractmethod\n    def step(self) -&gt; None:\n        \"\"\"\n        Performs one iteration/generation of the optimization algorithm.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_best(self) -&gt; Tuple[SolutionType, List[float]]:\n        \"\"\"\n        Returns the best solution and its corresponding objective value(s) found\n        so far.\n\n        Returns:\n            Tuple[SolutionType, List[float]]: A tuple containing:\n                - The best solution (of type SolutionType).\n                - The objective value(s) of the best solution.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/solver/#cilpy.solver.Solver.__init__","title":"<code>__init__(problem, **kwargs)</code>","text":"<p>Initializes the solver with a given problem and algorithm-specific parameters.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>Problem[SolutionType]</code> <p>The optimization problem to solve.</p> required <code>**kwargs</code> <p>Algorithm-specific parameters.</p> <code>{}</code> Source code in <code>cilpy/solver/__init__.py</code> <pre><code>def __init__(self, problem: Problem[SolutionType], **kwargs):\n    \"\"\"\n    Initializes the solver with a given problem and algorithm-specific\n    parameters.\n\n    Args:\n        problem (Problem[SolutionType]): The optimization problem to solve.\n        **kwargs: Algorithm-specific parameters.\n    \"\"\"\n    self.problem = problem\n</code></pre>"},{"location":"api/solver/#cilpy.solver.Solver.get_best","title":"<code>get_best()</code>  <code>abstractmethod</code>","text":"<p>Returns the best solution and its corresponding objective value(s) found so far.</p> <p>Returns:</p> Type Description <code>Tuple[SolutionType, List[float]]</code> <p>Tuple[SolutionType, List[float]]: A tuple containing: - The best solution (of type SolutionType). - The objective value(s) of the best solution.</p> Source code in <code>cilpy/solver/__init__.py</code> <pre><code>@abstractmethod\ndef get_best(self) -&gt; Tuple[SolutionType, List[float]]:\n    \"\"\"\n    Returns the best solution and its corresponding objective value(s) found\n    so far.\n\n    Returns:\n        Tuple[SolutionType, List[float]]: A tuple containing:\n            - The best solution (of type SolutionType).\n            - The objective value(s) of the best solution.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/solver/#cilpy.solver.Solver.step","title":"<code>step()</code>  <code>abstractmethod</code>","text":"<p>Performs one iteration/generation of the optimization algorithm.</p> Source code in <code>cilpy/solver/__init__.py</code> <pre><code>@abstractmethod\ndef step(self) -&gt; None:\n    \"\"\"\n    Performs one iteration/generation of the optimization algorithm.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/solver/#gbestpso","title":"GbestPSO","text":""},{"location":"api/solver/#cilpy.solver.pso.GbestPSO","title":"<code>cilpy.solver.pso.GbestPSO</code>","text":"<p>               Bases: <code>Solver[List[float]]</code></p> <p>Canonical global best Particle Swarm Optimization (PSO) solver.</p> <p>This version is adapted for dynamic optimization problems. It re-evaluates personal and global best solutions at the beginning of each step if the problem is dynamic, ensuring the swarm's memory is up-to-date with the current state of the fitness landscape.</p> Source code in <code>cilpy/solver/pso.py</code> <pre><code>class GbestPSO(Solver[List[float]]):\n    \"\"\"\n    Canonical global best Particle Swarm Optimization (PSO) solver.\n\n    This version is adapted for dynamic optimization problems. It re-evaluates\n    personal and global best solutions at the beginning of each step if the\n    problem is dynamic, ensuring the swarm's memory is up-to-date with the\n    current state of the fitness landscape.\n    \"\"\"\n\n    def __init__(\n        self,\n        problem: Problem[List[float]],\n        swarm_size: int = 30,\n        w: float = 0.729,\n        c1: float = 2.05,\n        c2: float = 2.05,\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initializes the PSO solver with a problem and algorithm parameters.\n        ... (rest of docstring is the same)\n        \"\"\"\n        super().__init__(problem, **kwargs)\n        self.swarm_size = swarm_size\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.objective = self.problem.get_objective_functions()[0]\n\n        # Initialize particles, velocities, personal bests, and global best\n        self.positions = [self.problem.initialize_solution() for _ in range(swarm_size)]\n        self.velocities = [self._initialize_velocity() for _ in range(swarm_size)]\n\n        self.pbest_positions = [p.copy() for p in self.positions]\n        self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n\n        # Initialize gbest based on the initial pbest values\n        self.gbest_idx = min(range(self.swarm_size), key=lambda i: self.pbest_values[i])\n        self.gbest_position = self.pbest_positions[self.gbest_idx]\n        self.gbest_value = self.pbest_values[self.gbest_idx]\n\n        # Store whether the problem is dynamic to avoid checks every step\n        self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n\n    def _initialize_velocity(self) -&gt; List[float]:\n        lower, upper = self.problem.get_bounds()\n        max_velocity = [abs(u - l) * 0.5 for l, u in zip(lower, upper)]\n        return [random.uniform(-v, v) for v in max_velocity]\n\n    def _clamp_position(self, position: List[float]) -&gt; List[float]:\n        lower, upper = self.problem.get_bounds()\n        return [min(max(x, l), u) for x, l, u in zip(position, lower, upper)]\n\n    def step(self) -&gt; None:\n        \"\"\"\n        Performs one iteration of the PSO algorithm, updating all particles.\n        \"\"\"\n        if self.is_dynamic or self.is_constrained_dynamic:\n            # Re-evaluate all personal best positions as their fitness may have changed\n            self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n\n            # Re-evaluate the global best position\n            self.gbest_value = self.objective(self.gbest_position)\n\n            # Check if any other particle's pbest is now better than the old gbest\n            current_best_idx = min(\n                range(self.swarm_size), key=lambda i: self.pbest_values[i]\n            )\n            if self.pbest_values[current_best_idx] &lt; self.gbest_value:\n                self.gbest_idx = current_best_idx\n                self.gbest_position = self.pbest_positions[self.gbest_idx]\n                self.gbest_value = self.pbest_values[self.gbest_idx]\n\n        # The main PSO loop proceeds with up-to-date fitness values for pbest/gbest\n        dimension = self.problem.get_dimension()\n        for i in range(self.swarm_size):\n            # Update velocity\n            new_velocity = []\n            for d in range(dimension):\n                r1, r2 = random.random(), random.random()\n                cognitive = (\n                    self.c1 * r1 * (self.pbest_positions[i][d] - self.positions[i][d])\n                )\n                social = self.c2 * r2 * (self.gbest_position[d] - self.positions[i][d])\n                velocity = self.w * self.velocities[i][d] + cognitive + social\n                new_velocity.append(velocity)\n            self.velocities[i] = new_velocity\n\n            # Update position\n            new_position = [\n                pos + vel for pos, vel in zip(self.positions[i], self.velocities[i])\n            ]\n            self.positions[i] = self._clamp_position(new_position)\n\n            # Evaluate new position\n            new_fitness = self.objective(self.positions[i])\n\n            # Update personal best\n            if new_fitness &lt; self.pbest_values[i]:\n                self.pbest_positions[i] = self.positions[i]\n                self.pbest_values[i] = new_fitness\n\n                # Update global best if this new pbest is the best found\n                if new_fitness &lt; self.gbest_value:\n                    self.gbest_position = self.positions[i]\n                    self.gbest_value = new_fitness\n                    self.gbest_idx = i\n\n    def get_best(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"\n        Returns the best solution and its objective value(s) found so far.\n        \"\"\"\n        return self.gbest_position, [self.gbest_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.pso.GbestPSO.__init__","title":"<code>__init__(problem, swarm_size=30, w=0.729, c1=2.05, c2=2.05, **kwargs)</code>","text":"<p>Initializes the PSO solver with a problem and algorithm parameters. ... (rest of docstring is the same)</p> Source code in <code>cilpy/solver/pso.py</code> <pre><code>def __init__(\n    self,\n    problem: Problem[List[float]],\n    swarm_size: int = 30,\n    w: float = 0.729,\n    c1: float = 2.05,\n    c2: float = 2.05,\n    **kwargs: Any\n):\n    \"\"\"\n    Initializes the PSO solver with a problem and algorithm parameters.\n    ... (rest of docstring is the same)\n    \"\"\"\n    super().__init__(problem, **kwargs)\n    self.swarm_size = swarm_size\n    self.w = w\n    self.c1 = c1\n    self.c2 = c2\n    self.objective = self.problem.get_objective_functions()[0]\n\n    # Initialize particles, velocities, personal bests, and global best\n    self.positions = [self.problem.initialize_solution() for _ in range(swarm_size)]\n    self.velocities = [self._initialize_velocity() for _ in range(swarm_size)]\n\n    self.pbest_positions = [p.copy() for p in self.positions]\n    self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n\n    # Initialize gbest based on the initial pbest values\n    self.gbest_idx = min(range(self.swarm_size), key=lambda i: self.pbest_values[i])\n    self.gbest_position = self.pbest_positions[self.gbest_idx]\n    self.gbest_value = self.pbest_values[self.gbest_idx]\n\n    # Store whether the problem is dynamic to avoid checks every step\n    self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n</code></pre>"},{"location":"api/solver/#cilpy.solver.pso.GbestPSO.get_best","title":"<code>get_best()</code>","text":"<p>Returns the best solution and its objective value(s) found so far.</p> Source code in <code>cilpy/solver/pso.py</code> <pre><code>def get_best(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"\n    Returns the best solution and its objective value(s) found so far.\n    \"\"\"\n    return self.gbest_position, [self.gbest_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.pso.GbestPSO.step","title":"<code>step()</code>","text":"<p>Performs one iteration of the PSO algorithm, updating all particles.</p> Source code in <code>cilpy/solver/pso.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"\n    Performs one iteration of the PSO algorithm, updating all particles.\n    \"\"\"\n    if self.is_dynamic or self.is_constrained_dynamic:\n        # Re-evaluate all personal best positions as their fitness may have changed\n        self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n\n        # Re-evaluate the global best position\n        self.gbest_value = self.objective(self.gbest_position)\n\n        # Check if any other particle's pbest is now better than the old gbest\n        current_best_idx = min(\n            range(self.swarm_size), key=lambda i: self.pbest_values[i]\n        )\n        if self.pbest_values[current_best_idx] &lt; self.gbest_value:\n            self.gbest_idx = current_best_idx\n            self.gbest_position = self.pbest_positions[self.gbest_idx]\n            self.gbest_value = self.pbest_values[self.gbest_idx]\n\n    # The main PSO loop proceeds with up-to-date fitness values for pbest/gbest\n    dimension = self.problem.get_dimension()\n    for i in range(self.swarm_size):\n        # Update velocity\n        new_velocity = []\n        for d in range(dimension):\n            r1, r2 = random.random(), random.random()\n            cognitive = (\n                self.c1 * r1 * (self.pbest_positions[i][d] - self.positions[i][d])\n            )\n            social = self.c2 * r2 * (self.gbest_position[d] - self.positions[i][d])\n            velocity = self.w * self.velocities[i][d] + cognitive + social\n            new_velocity.append(velocity)\n        self.velocities[i] = new_velocity\n\n        # Update position\n        new_position = [\n            pos + vel for pos, vel in zip(self.positions[i], self.velocities[i])\n        ]\n        self.positions[i] = self._clamp_position(new_position)\n\n        # Evaluate new position\n        new_fitness = self.objective(self.positions[i])\n\n        # Update personal best\n        if new_fitness &lt; self.pbest_values[i]:\n            self.pbest_positions[i] = self.positions[i]\n            self.pbest_values[i] = new_fitness\n\n            # Update global best if this new pbest is the best found\n            if new_fitness &lt; self.gbest_value:\n                self.gbest_position = self.positions[i]\n                self.gbest_value = new_fitness\n                self.gbest_idx = i\n</code></pre>"},{"location":"api/solver/#qpsosolver","title":"QPSOSolver","text":""},{"location":"api/solver/#cilpy.solver.qpso.QPSOSolver","title":"<code>cilpy.solver.qpso.QPSOSolver</code>","text":"<p>               Bases: <code>Solver[List[float]]</code></p> <p>Quantum-Inspired Particle Swarm Optimization (QPSO) solver.</p> <p>This solver implements the QPSO algorithm, which differs from canonical PSO by eliminating the velocity vector. Instead, particles are attracted to a stochastic point within the problem space.</p> <p>This implementation is adapted for dynamic optimization problems by re-evaluating memory (pbest/gbest) at the start of each step.</p> Source code in <code>cilpy/solver/qpso.py</code> <pre><code>class QPSOSolver(Solver[List[float]]):\n    \"\"\"\n    Quantum-Inspired Particle Swarm Optimization (QPSO) solver.\n\n    This solver implements the QPSO algorithm, which differs from canonical PSO\n    by eliminating the velocity vector. Instead, particles are attracted to a\n    stochastic point within the problem space.\n\n    This implementation is adapted for dynamic optimization problems by\n    re-evaluating memory (pbest/gbest) at the start of each step.\n    \"\"\"\n\n    def __init__(\n        self,\n        problem: Problem[List[float]],\n        swarm_size: int = 30,\n        alpha_start: float = 1.0,\n        alpha_end: float = 0.5,\n        max_iterations: int = 1000,\n        distribution: str = \"uniform\",\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initializes the QPSO solver.\n\n        Args:\n            problem: The optimization problem to solve.\n            swarm_size: Number of particles in the swarm.\n            alpha_start: Initial value for the contraction-expansion coefficient.\n            alpha_end: Final value for the contraction-expansion coefficient.\n            max_iterations: The total number of iterations for the run. This is\n                            required to schedule the linear decrease of alpha.\n            distribution: The sampling strategy for updating positions.\n                          Can be 'uniform' or 'gaussian'.\n            **kwargs: Additional parameters (ignored).\n        \"\"\"\n        super().__init__(problem, **kwargs)\n        self.swarm_size = swarm_size\n        self.alpha_start = alpha_start\n        self.alpha_end = alpha_end\n        self.max_iterations = max_iterations\n        self.iteration = 0\n        self.objective = self.problem.get_objective_functions()[0]\n        self.dimension = self.problem.get_dimension()\n\n        # Set the distribution strategy\n        if distribution.lower() == \"uniform\":\n            self.distribution_strategy = _uniform_distribution\n        elif distribution.lower() == \"gaussian\":\n            self.distribution_strategy = _gaussian_distribution\n        else:\n            raise ValueError(\"Distribution must be 'uniform' or 'gaussian'.\")\n\n        # Initialize particles and global best\n        self.positions = [\n            self.problem.initialize_solution() for _ in range(self.swarm_size)\n        ]\n        self.pbest_positions = [p.copy() for p in self.positions]\n        self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n\n        self.gbest_idx = min(range(self.swarm_size), key=lambda i: self.pbest_values[i])\n        self.gbest_position = self.pbest_positions[self.gbest_idx]\n        self.gbest_value = self.pbest_values[self.gbest_idx]\n\n        # Store dynamic status to avoid repeated checks\n        self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n\n    def _clamp_position(self, position: List[float]) -&gt; List[float]:\n        \"\"\"Clamps a position to the problem's bounds.\"\"\"\n        lower, upper = self.problem.get_bounds()\n        return [max(l, min(x, u)) for x, l, u in zip(position, lower, upper)]\n\n    def step(self) -&gt; None:\n        \"\"\"Performs one iteration of the QPSO algorithm.\"\"\"\n\n        # 1. Re-evaluate memory if the environment is dynamic\n        if self.is_dynamic or self.is_constrained_dynamic:\n            self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n            self.gbest_value = self.objective(self.gbest_position)\n\n            current_best_idx = min(\n                range(self.swarm_size), key=lambda i: self.pbest_values[i]\n            )\n            if self.pbest_values[current_best_idx] &lt; self.gbest_value:\n                self.gbest_idx = current_best_idx\n                self.gbest_position = self.pbest_positions[self.gbest_idx]\n                self.gbest_value = self.pbest_values[self.gbest_idx]\n\n        # 2. Calculate the mean best position (mbest)\n        mbest_pos = [\n            sum(p[d] for p in self.pbest_positions) / self.swarm_size\n            for d in range(self.dimension)\n        ]\n\n        # 3. Update alpha (linearly decreasing contraction-expansion coefficient)\n        alpha = self.alpha_start - (self.iteration / self.max_iterations) * (\n            self.alpha_start - self.alpha_end\n        )\n\n        # 4. Update particle positions and evaluate\n        for i in range(self.swarm_size):\n            new_position = []\n            for d in range(self.dimension):\n                # Calculate the local attractor for each dimension\n                phi = random.random()\n                local_attractor = (\n                    phi * self.pbest_positions[i][d]\n                    + (1 - phi) * self.gbest_position[d]\n                )\n\n                # Calculate the new position for this dimension\n                new_pos_d = self.distribution_strategy(\n                    local_attractor, self.positions[i][d], mbest_pos[d], alpha\n                )\n                new_position.append(new_pos_d)\n\n            # Update and clamp the full position vector\n            self.positions[i] = self._clamp_position(new_position)\n\n            # Evaluate new position\n            new_fitness = self.objective(self.positions[i])\n\n            # Update personal best\n            if new_fitness &lt; self.pbest_values[i]:\n                self.pbest_positions[i] = self.positions[i]\n                self.pbest_values[i] = new_fitness\n\n                # Update global best\n                if new_fitness &lt; self.gbest_value:\n                    self.gbest_position = self.positions[i]\n                    self.gbest_value = new_fitness\n                    self.gbest_idx = i\n\n        self.iteration += 1\n\n    def get_best(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"Returns the best solution and its objective value found so far.\"\"\"\n        return self.gbest_position, [self.gbest_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.qpso.QPSOSolver.__init__","title":"<code>__init__(problem, swarm_size=30, alpha_start=1.0, alpha_end=0.5, max_iterations=1000, distribution='uniform', **kwargs)</code>","text":"<p>Initializes the QPSO solver.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>Problem[List[float]]</code> <p>The optimization problem to solve.</p> required <code>swarm_size</code> <code>int</code> <p>Number of particles in the swarm.</p> <code>30</code> <code>alpha_start</code> <code>float</code> <p>Initial value for the contraction-expansion coefficient.</p> <code>1.0</code> <code>alpha_end</code> <code>float</code> <p>Final value for the contraction-expansion coefficient.</p> <code>0.5</code> <code>max_iterations</code> <code>int</code> <p>The total number of iterations for the run. This is             required to schedule the linear decrease of alpha.</p> <code>1000</code> <code>distribution</code> <code>str</code> <p>The sampling strategy for updating positions.           Can be 'uniform' or 'gaussian'.</p> <code>'uniform'</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters (ignored).</p> <code>{}</code> Source code in <code>cilpy/solver/qpso.py</code> <pre><code>def __init__(\n    self,\n    problem: Problem[List[float]],\n    swarm_size: int = 30,\n    alpha_start: float = 1.0,\n    alpha_end: float = 0.5,\n    max_iterations: int = 1000,\n    distribution: str = \"uniform\",\n    **kwargs: Any\n):\n    \"\"\"\n    Initializes the QPSO solver.\n\n    Args:\n        problem: The optimization problem to solve.\n        swarm_size: Number of particles in the swarm.\n        alpha_start: Initial value for the contraction-expansion coefficient.\n        alpha_end: Final value for the contraction-expansion coefficient.\n        max_iterations: The total number of iterations for the run. This is\n                        required to schedule the linear decrease of alpha.\n        distribution: The sampling strategy for updating positions.\n                      Can be 'uniform' or 'gaussian'.\n        **kwargs: Additional parameters (ignored).\n    \"\"\"\n    super().__init__(problem, **kwargs)\n    self.swarm_size = swarm_size\n    self.alpha_start = alpha_start\n    self.alpha_end = alpha_end\n    self.max_iterations = max_iterations\n    self.iteration = 0\n    self.objective = self.problem.get_objective_functions()[0]\n    self.dimension = self.problem.get_dimension()\n\n    # Set the distribution strategy\n    if distribution.lower() == \"uniform\":\n        self.distribution_strategy = _uniform_distribution\n    elif distribution.lower() == \"gaussian\":\n        self.distribution_strategy = _gaussian_distribution\n    else:\n        raise ValueError(\"Distribution must be 'uniform' or 'gaussian'.\")\n\n    # Initialize particles and global best\n    self.positions = [\n        self.problem.initialize_solution() for _ in range(self.swarm_size)\n    ]\n    self.pbest_positions = [p.copy() for p in self.positions]\n    self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n\n    self.gbest_idx = min(range(self.swarm_size), key=lambda i: self.pbest_values[i])\n    self.gbest_position = self.pbest_positions[self.gbest_idx]\n    self.gbest_value = self.pbest_values[self.gbest_idx]\n\n    # Store dynamic status to avoid repeated checks\n    self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n</code></pre>"},{"location":"api/solver/#cilpy.solver.qpso.QPSOSolver.get_best","title":"<code>get_best()</code>","text":"<p>Returns the best solution and its objective value found so far.</p> Source code in <code>cilpy/solver/qpso.py</code> <pre><code>def get_best(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"Returns the best solution and its objective value found so far.\"\"\"\n    return self.gbest_position, [self.gbest_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.qpso.QPSOSolver.step","title":"<code>step()</code>","text":"<p>Performs one iteration of the QPSO algorithm.</p> Source code in <code>cilpy/solver/qpso.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"Performs one iteration of the QPSO algorithm.\"\"\"\n\n    # 1. Re-evaluate memory if the environment is dynamic\n    if self.is_dynamic or self.is_constrained_dynamic:\n        self.pbest_values = [self.objective(pos) for pos in self.pbest_positions]\n        self.gbest_value = self.objective(self.gbest_position)\n\n        current_best_idx = min(\n            range(self.swarm_size), key=lambda i: self.pbest_values[i]\n        )\n        if self.pbest_values[current_best_idx] &lt; self.gbest_value:\n            self.gbest_idx = current_best_idx\n            self.gbest_position = self.pbest_positions[self.gbest_idx]\n            self.gbest_value = self.pbest_values[self.gbest_idx]\n\n    # 2. Calculate the mean best position (mbest)\n    mbest_pos = [\n        sum(p[d] for p in self.pbest_positions) / self.swarm_size\n        for d in range(self.dimension)\n    ]\n\n    # 3. Update alpha (linearly decreasing contraction-expansion coefficient)\n    alpha = self.alpha_start - (self.iteration / self.max_iterations) * (\n        self.alpha_start - self.alpha_end\n    )\n\n    # 4. Update particle positions and evaluate\n    for i in range(self.swarm_size):\n        new_position = []\n        for d in range(self.dimension):\n            # Calculate the local attractor for each dimension\n            phi = random.random()\n            local_attractor = (\n                phi * self.pbest_positions[i][d]\n                + (1 - phi) * self.gbest_position[d]\n            )\n\n            # Calculate the new position for this dimension\n            new_pos_d = self.distribution_strategy(\n                local_attractor, self.positions[i][d], mbest_pos[d], alpha\n            )\n            new_position.append(new_pos_d)\n\n        # Update and clamp the full position vector\n        self.positions[i] = self._clamp_position(new_position)\n\n        # Evaluate new position\n        new_fitness = self.objective(self.positions[i])\n\n        # Update personal best\n        if new_fitness &lt; self.pbest_values[i]:\n            self.pbest_positions[i] = self.positions[i]\n            self.pbest_values[i] = new_fitness\n\n            # Update global best\n            if new_fitness &lt; self.gbest_value:\n                self.gbest_position = self.positions[i]\n                self.gbest_value = new_fitness\n                self.gbest_idx = i\n\n    self.iteration += 1\n</code></pre>"},{"location":"api/solver/#differentialevolutionsolver","title":"DifferentialEvolutionSolver","text":""},{"location":"api/solver/#cilpy.solver.de_rand_1_bin.DifferentialEvolutionSolver","title":"<code>cilpy.solver.de_rand_1_bin.DifferentialEvolutionSolver</code>","text":"<p>               Bases: <code>Solver[List[float]]</code></p> <p>Implements the classic DE/rand/1/bin Differential Evolution algorithm.</p> <ul> <li>rand: The base vector for mutation is chosen randomly.</li> <li>1: One difference vector is used for mutation.</li> <li>bin: Binomial (uniform) crossover is used.</li> </ul> <p>This solver is adapted for dynamic optimization problems by re-evaluating the entire population's fitness at the start of each step if the environment has changed.</p> Source code in <code>cilpy/solver/de_rand_1_bin.py</code> <pre><code>class DifferentialEvolutionSolver(Solver[List[float]]):\n    \"\"\"\n    Implements the classic DE/rand/1/bin Differential Evolution algorithm.\n\n    - **rand**: The base vector for mutation is chosen randomly.\n    - **1**: One difference vector is used for mutation.\n    - **bin**: Binomial (uniform) crossover is used.\n\n    This solver is adapted for dynamic optimization problems by re-evaluating the\n    entire population's fitness at the start of each step if the environment\n    has changed.\n    \"\"\"\n\n    def __init__(\n        self,\n        problem: Problem[List[float]],\n        population_size: int = 50,\n        scale_factor: float = 0.8,\n        crossover_prob: float = 0.9,\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initializes the Differential Evolution solver.\n\n        Args:\n            problem: The optimization problem to solve.\n            population_size: The number of individuals in the population (NP).\n            scale_factor: The mutation factor (F), usually in [0.4, 1.0].\n            crossover_prob: The crossover probability (CR), usually in [0, 1].\n            **kwargs: Additional parameters (ignored).\n        \"\"\"\n        super().__init__(problem, **kwargs)\n        self.population_size = population_size\n        self.f = scale_factor  # F\n        self.cr = crossover_prob  # CR\n        self.objective = self.problem.get_objective_functions()[0]\n        self.dimension = self.problem.get_dimension()\n\n        # Initialize population and evaluate fitness\n        self.population = [\n            self.problem.initialize_solution() for _ in range(self.population_size)\n        ]\n        self.fitness = [self.objective(ind) for ind in self.population]\n\n        # Find initial global best\n        best_idx = min(range(self.population_size), key=lambda i: self.fitness[i])\n        self.gbest_position = self.population[best_idx]\n        self.gbest_value = self.fitness[best_idx]\n\n        # Store dynamic status\n        self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n\n    def _clamp_position(self, position: List[float]) -&gt; List[float]:\n        \"\"\"Clamps a position to the problem's bounds.\"\"\"\n        lower, upper = self.problem.get_bounds()\n        return [max(l, min(x, u)) for x, l, u in zip(position, lower, upper)]\n\n    def step(self) -&gt; None:\n        \"\"\"Performs one generation of the DE algorithm.\"\"\"\n\n        # Re-evaluate population if the environment is dynamic\n        if self.is_dynamic or self.is_constrained_dynamic:\n            self.fitness = [self.objective(ind) for ind in self.population]\n            # After re-evaluation, find the new best solution\n            best_idx = min(range(self.population_size), key=lambda i: self.fitness[i])\n            self.gbest_position = self.population[best_idx]\n            self.gbest_value = self.fitness[best_idx]\n\n        # Main DE loop for one generation\n        for i in range(self.population_size):\n            # --- Mutation ---\n            # Select three distinct individuals other than the current one\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            r1, r2, r3 = random.sample(indices, 3)\n\n            # Create the mutant vector v = x_r1 + F * (x_r2 - x_r3)\n            mutant_vector = [\n                self.population[r1][d]\n                + self.f * (self.population[r2][d] - self.population[r3][d])\n                for d in range(self.dimension)\n            ]\n            mutant_vector = self._clamp_position(mutant_vector)\n\n            # --- Crossover ---\n            # Create the trial vector by binomial crossover\n            trial_vector = []\n            j_rand = random.randrange(self.dimension)\n            for d in range(self.dimension):\n                if random.random() &lt; self.cr or d == j_rand:\n                    trial_vector.append(mutant_vector[d])\n                else:\n                    trial_vector.append(self.population[i][d])\n\n            # --- Selection ---\n            trial_fitness = self.objective(trial_vector)\n\n            # If the trial vector is better, it replaces the target vector\n            if trial_fitness &lt; self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n\n                # Update the global best if necessary\n                if trial_fitness &lt; self.gbest_value:\n                    self.gbest_value = trial_fitness\n                    self.gbest_position = trial_vector\n\n    def get_best(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"Returns the best solution and its objective value found so far.\"\"\"\n        return self.gbest_position, [self.gbest_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.de_rand_1_bin.DifferentialEvolutionSolver.__init__","title":"<code>__init__(problem, population_size=50, scale_factor=0.8, crossover_prob=0.9, **kwargs)</code>","text":"<p>Initializes the Differential Evolution solver.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>Problem[List[float]]</code> <p>The optimization problem to solve.</p> required <code>population_size</code> <code>int</code> <p>The number of individuals in the population (NP).</p> <code>50</code> <code>scale_factor</code> <code>float</code> <p>The mutation factor (F), usually in [0.4, 1.0].</p> <code>0.8</code> <code>crossover_prob</code> <code>float</code> <p>The crossover probability (CR), usually in [0, 1].</p> <code>0.9</code> <code>**kwargs</code> <code>Any</code> <p>Additional parameters (ignored).</p> <code>{}</code> Source code in <code>cilpy/solver/de_rand_1_bin.py</code> <pre><code>def __init__(\n    self,\n    problem: Problem[List[float]],\n    population_size: int = 50,\n    scale_factor: float = 0.8,\n    crossover_prob: float = 0.9,\n    **kwargs: Any\n):\n    \"\"\"\n    Initializes the Differential Evolution solver.\n\n    Args:\n        problem: The optimization problem to solve.\n        population_size: The number of individuals in the population (NP).\n        scale_factor: The mutation factor (F), usually in [0.4, 1.0].\n        crossover_prob: The crossover probability (CR), usually in [0, 1].\n        **kwargs: Additional parameters (ignored).\n    \"\"\"\n    super().__init__(problem, **kwargs)\n    self.population_size = population_size\n    self.f = scale_factor  # F\n    self.cr = crossover_prob  # CR\n    self.objective = self.problem.get_objective_functions()[0]\n    self.dimension = self.problem.get_dimension()\n\n    # Initialize population and evaluate fitness\n    self.population = [\n        self.problem.initialize_solution() for _ in range(self.population_size)\n    ]\n    self.fitness = [self.objective(ind) for ind in self.population]\n\n    # Find initial global best\n    best_idx = min(range(self.population_size), key=lambda i: self.fitness[i])\n    self.gbest_position = self.population[best_idx]\n    self.gbest_value = self.fitness[best_idx]\n\n    # Store dynamic status\n    self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n</code></pre>"},{"location":"api/solver/#cilpy.solver.de_rand_1_bin.DifferentialEvolutionSolver.get_best","title":"<code>get_best()</code>","text":"<p>Returns the best solution and its objective value found so far.</p> Source code in <code>cilpy/solver/de_rand_1_bin.py</code> <pre><code>def get_best(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"Returns the best solution and its objective value found so far.\"\"\"\n    return self.gbest_position, [self.gbest_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.de_rand_1_bin.DifferentialEvolutionSolver.step","title":"<code>step()</code>","text":"<p>Performs one generation of the DE algorithm.</p> Source code in <code>cilpy/solver/de_rand_1_bin.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"Performs one generation of the DE algorithm.\"\"\"\n\n    # Re-evaluate population if the environment is dynamic\n    if self.is_dynamic or self.is_constrained_dynamic:\n        self.fitness = [self.objective(ind) for ind in self.population]\n        # After re-evaluation, find the new best solution\n        best_idx = min(range(self.population_size), key=lambda i: self.fitness[i])\n        self.gbest_position = self.population[best_idx]\n        self.gbest_value = self.fitness[best_idx]\n\n    # Main DE loop for one generation\n    for i in range(self.population_size):\n        # --- Mutation ---\n        # Select three distinct individuals other than the current one\n        indices = list(range(self.population_size))\n        indices.remove(i)\n        r1, r2, r3 = random.sample(indices, 3)\n\n        # Create the mutant vector v = x_r1 + F * (x_r2 - x_r3)\n        mutant_vector = [\n            self.population[r1][d]\n            + self.f * (self.population[r2][d] - self.population[r3][d])\n            for d in range(self.dimension)\n        ]\n        mutant_vector = self._clamp_position(mutant_vector)\n\n        # --- Crossover ---\n        # Create the trial vector by binomial crossover\n        trial_vector = []\n        j_rand = random.randrange(self.dimension)\n        for d in range(self.dimension):\n            if random.random() &lt; self.cr or d == j_rand:\n                trial_vector.append(mutant_vector[d])\n            else:\n                trial_vector.append(self.population[i][d])\n\n        # --- Selection ---\n        trial_fitness = self.objective(trial_vector)\n\n        # If the trial vector is better, it replaces the target vector\n        if trial_fitness &lt; self.fitness[i]:\n            self.population[i] = trial_vector\n            self.fitness[i] = trial_fitness\n\n            # Update the global best if necessary\n            if trial_fitness &lt; self.gbest_value:\n                self.gbest_value = trial_fitness\n                self.gbest_position = trial_vector\n</code></pre>"},{"location":"api/solver/#ccpsosolver","title":"CCPSOSolver","text":""},{"location":"api/solver/#cilpy.solver.ccpso.CCPSO","title":"<code>cilpy.solver.ccpso.CCPSO</code>","text":"<p>               Bases: <code>Solver[List[float]]</code></p> <p>Co-evolutionary Particle Swarm Optimisation (CCPSO) for constrained problems.</p> <p>This algorithm, inspired by Shi and Krohling, uses a co-evolutionary approach to handle constraints. It decomposes the problem into two sub-problems, solved by two cooperating PSO swarms:</p> <ol> <li>Objective Swarm (P1): Searches the solution space for variables 'x'.     Its goal is to MINIMIZE the Lagrangian function.</li> <li>Penalty Swarm (P2): Searches the space of Lagrangian multipliers     ('\u03bc' for inequality, '\u03bb' for equality constraints). Its goal is to     MAXIMIZE the Lagrangian function.</li> </ol> <p>The fitness of each particle in one swarm is evaluated using the global best solution from the other swarm. This creates a co-evolutionary, min-max dynamic.</p> <p>This implementation is also adapted for dynamic constrained optimization problems (DCOPs) by re-evaluating personal and global bests if the problem's landscape changes.</p> References <p>Y. Shi and R. A. Krohling. (2002). \u201cCo-Evolutionary Particle Swarm Optimization To Solve Min-Max Problems\u201d.</p> Source code in <code>cilpy/solver/ccpso.py</code> <pre><code>class CCPSO(Solver[List[float]]):\n    \"\"\"\n    Co-evolutionary Particle Swarm Optimisation (CCPSO) for constrained problems.\n\n    This algorithm, inspired by Shi and Krohling, uses a co-evolutionary\n    approach to handle constraints. It decomposes the problem into two\n    sub-problems, solved by two cooperating PSO swarms:\n\n    1.  **Objective Swarm (P1)**: Searches the solution space for variables 'x'.\n        Its goal is to MINIMIZE the Lagrangian function.\n    2.  **Penalty Swarm (P2)**: Searches the space of Lagrangian multipliers\n        ('\u03bc' for inequality, '\u03bb' for equality constraints). Its goal is to\n        MAXIMIZE the Lagrangian function.\n\n    The fitness of each particle in one swarm is evaluated using the global best\n    solution from the other swarm. This creates a co-evolutionary, min-max\n    dynamic.\n\n    This implementation is also adapted for dynamic constrained optimization\n    problems (DCOPs) by re-evaluating personal and global bests if the\n    problem's landscape changes.\n\n    References:\n        Y. Shi and R. A. Krohling. (2002). \u201cCo-Evolutionary Particle Swarm\n        Optimization To Solve Min-Max Problems\u201d.\n    \"\"\"\n\n    def __init__(\n        self,\n        problem: Problem[List[float]],\n        swarm_size_x: int = 30,\n        swarm_size_l: int = 30,\n        w: float = 0.729,\n        c1: float = 2.05,\n        c2: float = 2.05,\n        lambda_bounds: Tuple[float, float] = (0.0, 1000.0),\n        **kwargs: Any\n    ):\n        \"\"\"\n        Initializes the CCPSO solver.\n\n        Args:\n            problem (Problem[List[float]]): The constrained optimization problem.\n            swarm_size_x (int): The number of particles in the objective swarm.\n            swarm_size_l (int): The number of particles in the penalty swarm.\n            w (float): Inertia weight for both PSOs.\n            c1 (float): Cognitive coefficient for both PSOs.\n            c2 (float): Social coefficient for both PSOs.\n            lambda_bounds (Tuple[float, float]): The search space for Lagrangian\n                                                 multipliers.\n            **kwargs: Additional arguments for the base Solver class.\n        \"\"\"\n        super().__init__(problem, **kwargs)\n\n        # PSO parameters\n        self.w = w\n        self.c1 = c1\n        self.c2 = c2\n        self.swarm_size_x = swarm_size_x\n        self.swarm_size_l = swarm_size_l\n\n        # Problem-specific information\n        self.objective = self.problem.get_objective_functions()[0]\n        self.inequality_constraints, self.equality_constraints = (\n            self.problem.get_constraint_functions()\n        )\n        self.lambda_dim = len(self.inequality_constraints) + len(\n            self.equality_constraints\n        )\n        self.lambda_bounds = lambda_bounds\n        self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n\n        # --- Initialize Objective Swarm (P1 for x) ---\n        self.positions_x = [\n            self.problem.initialize_solution() for _ in range(self.swarm_size_x)\n        ]\n        self.velocities_x = [\n            self._initialize_velocity(self.problem.get_bounds())\n            for _ in range(self.swarm_size_x)\n        ]\n        self.pbest_positions_x = [p.copy() for p in self.positions_x]\n\n        # --- Initialize Penalty Swarm (P2 for \u03bc, \u03bb) ---\n        if self.lambda_dim &gt; 0:\n            self.positions_l = [\n                self._initialize_lambda_particle() for _ in range(self.swarm_size_l)\n            ]\n            l_lower_bounds = [self.lambda_bounds[0]] * self.lambda_dim\n            l_upper_bounds = [self.lambda_bounds[1]] * self.lambda_dim\n            self.bounds_l = (l_lower_bounds, l_upper_bounds)  # &lt;-- Note the 'self.'\n            self.velocities_l = [\n                self._initialize_velocity(self.bounds_l)\n                for _ in range(self.swarm_size_l)\n            ]  # &lt;-- Use self.bounds_l\n            self.pbest_positions_l = [p.copy() for p in self.positions_l]\n            # Initialize a placeholder gbest lambda for the first evaluation of swarm X\n            self.gbest_position_l = self._initialize_lambda_particle()\n        else:  # Unconstrained problem\n            self.positions_l, self.velocities_l, self.pbest_positions_l = [], [], []\n            self.gbest_position_l = []\n            self.bounds_l = ([], [])  # Initialize to avoid attribute errors\n\n        # --- Initial Evaluation and Best Finding ---\n        # Evaluate pbest_x using the initial placeholder gbest_l\n        self.pbest_values_x = [\n            self._calculate_lagrangian(pos, self.gbest_position_l)\n            for pos in self.pbest_positions_x\n        ]\n\n        # Find gbest_x based on initial evaluation\n        gbest_idx_x = min(\n            range(self.swarm_size_x), key=lambda i: self.pbest_values_x[i]\n        )\n        self.gbest_position_x = self.pbest_positions_x[gbest_idx_x]\n        self.gbest_value_x = self.pbest_values_x[gbest_idx_x]\n\n        if self.lambda_dim &gt; 0:\n            # Evaluate pbest_l using the newly found gbest_x\n            self.pbest_values_l = [\n                self._calculate_lagrangian(self.gbest_position_x, pos)\n                for pos in self.pbest_positions_l\n            ]\n\n            # Find gbest_l (maximization)\n            gbest_idx_l = max(\n                range(self.swarm_size_l), key=lambda i: self.pbest_values_l[i]\n            )\n            self.gbest_position_l = self.pbest_positions_l[gbest_idx_l]\n            self.gbest_value_l = self.pbest_values_l[gbest_idx_l]\n\n    def _calculate_lagrangian(self, x: List[float], lag_mult: List[float]) -&gt; float:\n        \"\"\"\n        Calculates the value of the Lagrangian function L(x, \u03bc, \u03bb).\n        L(x, \u03bc, \u03bb) = f(x) + \u03a3(\u03bc_i * max(0, g_i(x))) + \u03a3(\u03bb_j * |h_j(x)|)\n        \"\"\"\n        obj_val = self.objective(x)\n\n        if not self.lambda_dim:\n            return obj_val\n\n        # Unpack multipliers\n        num_ineq = len(self.inequality_constraints)\n        mu = lag_mult[:num_ineq]\n        lam = lag_mult[num_ineq:]\n\n        # Inequality constraint penalty (g_i(x) &lt;= 0)\n        ineq_penalty = sum(\n            m * max(0, const(x)) for m, const in zip(mu, self.inequality_constraints)\n        )\n\n        # Equality constraint penalty (h_j(x) = 0)\n        eq_penalty = sum(\n            l * abs(const(x)) for l, const in zip(lam, self.equality_constraints)\n        )\n\n        return obj_val + ineq_penalty + eq_penalty\n\n    def _initialize_velocity(\n        self, bounds: Tuple[List[float], List[float]]\n    ) -&gt; List[float]:\n        lower_bounds, upper_bounds = bounds  # Unpack the tuple of lists\n        max_velocity = [abs(u - l) * 0.5 for l, u in zip(lower_bounds, upper_bounds)]\n        return [random.uniform(-v, v) for v in max_velocity]\n\n    def _initialize_lambda_particle(self) -&gt; List[float]:\n        return [random.uniform(*self.lambda_bounds) for _ in range(self.lambda_dim)]\n\n    def _clamp_position(\n        self, position: List[float], bounds: Tuple[List[float], List[float]]\n    ) -&gt; List[float]:\n        lower_bounds, upper_bounds = bounds\n        return [\n            min(max(x, l), u) for x, l, u in zip(position, lower_bounds, upper_bounds)\n        ]\n\n    # def _clamp_position(self, position: List[float], bounds: Any) -&gt; List[float]:\n    #     return [min(max(x, b[0]), b[1]) for x, b in zip(position, bounds)]\n\n    def step(self) -&gt; None:\n        \"\"\"Performs one co-evolutionary iteration.\"\"\"\n        if self.is_dynamic or self.is_constrained_dynamic:\n            # Re-evaluate all personal bests and global bests as fitness may have changed\n            self.pbest_values_x = [\n                self._calculate_lagrangian(pos, self.gbest_position_l)\n                for pos in self.pbest_positions_x\n            ]\n            self.gbest_value_x = self._calculate_lagrangian(\n                self.gbest_position_x, self.gbest_position_l\n            )\n\n            # Check if any other pbest_x is now better than the old gbest_x\n            current_best_idx_x = min(\n                range(self.swarm_size_x), key=lambda i: self.pbest_values_x[i]\n            )\n            if self.pbest_values_x[current_best_idx_x] &lt; self.gbest_value_x:\n                self.gbest_position_x = self.pbest_positions_x[current_best_idx_x]\n                self.gbest_value_x = self.pbest_values_x[current_best_idx_x]\n\n            if self.lambda_dim &gt; 0:\n                self.pbest_values_l = [\n                    self._calculate_lagrangian(self.gbest_position_x, pos)\n                    for pos in self.pbest_positions_l\n                ]\n                self.gbest_value_l = self._calculate_lagrangian(\n                    self.gbest_position_x, self.gbest_position_l\n                )\n\n                # Check if any other pbest_l is now better than the old gbest_l (maximization)\n                current_best_idx_l = max(\n                    range(self.swarm_size_l), key=lambda i: self.pbest_values_l[i]\n                )\n                if self.pbest_values_l[current_best_idx_l] &gt; self.gbest_value_l:\n                    self.gbest_position_l = self.pbest_positions_l[current_best_idx_l]\n                    self.gbest_value_l = self.pbest_values_l[current_best_idx_l]\n\n        # --- 1. Update Objective Swarm (P1) - Minimization ---\n        dim_x = self.problem.get_dimension()\n        bounds_x = self.problem.get_bounds()\n        for i in range(self.swarm_size_x):\n            # Update velocity\n            new_velocity = []\n            for d in range(dim_x):\n                r1, r2 = random.random(), random.random()\n                cognitive = (\n                    self.c1\n                    * r1\n                    * (self.pbest_positions_x[i][d] - self.positions_x[i][d])\n                )\n                social = (\n                    self.c2 * r2 * (self.gbest_position_x[d] - self.positions_x[i][d])\n                )\n                velocity = self.w * self.velocities_x[i][d] + cognitive + social\n                new_velocity.append(velocity)\n            self.velocities_x[i] = new_velocity\n\n            # Update position\n            new_position = [\n                pos + vel for pos, vel in zip(self.positions_x[i], self.velocities_x[i])\n            ]\n            self.positions_x[i] = self._clamp_position(new_position, bounds_x)\n\n            # Evaluate using gbest from penalty swarm\n            new_fitness = self._calculate_lagrangian(\n                self.positions_x[i], self.gbest_position_l\n            )\n\n            # Update personal best (minimization)\n            if new_fitness &lt; self.pbest_values_x[i]:\n                self.pbest_positions_x[i] = self.positions_x[i]\n                self.pbest_values_x[i] = new_fitness\n\n                # Update global best\n                if new_fitness &lt; self.gbest_value_x:\n                    self.gbest_position_x = self.positions_x[i]\n                    self.gbest_value_x = new_fitness\n\n        # --- 2. Update Penalty Swarm (P2) - Maximization ---\n        if self.lambda_dim &gt; 0:\n            for i in range(self.swarm_size_l):\n                # Update velocity\n                new_velocity = []\n                for d in range(self.lambda_dim):\n                    r1, r2 = random.random(), random.random()\n                    cognitive = (\n                        self.c1\n                        * r1\n                        * (self.pbest_positions_l[i][d] - self.positions_l[i][d])\n                    )\n                    social = (\n                        self.c2\n                        * r2\n                        * (self.gbest_position_l[d] - self.positions_l[i][d])\n                    )\n                    velocity = self.w * self.velocities_l[i][d] + cognitive + social\n                    new_velocity.append(velocity)\n                self.velocities_l[i] = new_velocity\n\n                # Update position\n                new_position = [\n                    pos + vel\n                    for pos, vel in zip(self.positions_l[i], self.velocities_l[i])\n                ]\n                self.positions_l[i] = self._clamp_position(new_position, self.bounds_l)\n\n                # Evaluate using gbest from objective swarm\n                new_fitness = self._calculate_lagrangian(\n                    self.gbest_position_x, self.positions_l[i]\n                )\n\n                # Update personal best (maximization)\n                if new_fitness &gt; self.pbest_values_l[i]:\n                    self.pbest_positions_l[i] = self.positions_l[i]\n                    self.pbest_values_l[i] = new_fitness\n\n                    # Update global best\n                    if new_fitness &gt; self.gbest_value_l:\n                        self.gbest_position_l = self.positions_l[i]\n                        self.gbest_value_l = new_fitness\n\n    def get_best(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"\n        Returns the best solution 'x' and its raw objective value (not the\n        Lagrangian value).\n        \"\"\"\n        # The user is interested in the objective function value of the best\n        # solution, not its Lagrangian fitness.\n        best_objective_value = self.objective(self.gbest_position_x)\n        return self.gbest_position_x, [best_objective_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.ccpso.CCPSO.__init__","title":"<code>__init__(problem, swarm_size_x=30, swarm_size_l=30, w=0.729, c1=2.05, c2=2.05, lambda_bounds=(0.0, 1000.0), **kwargs)</code>","text":"<p>Initializes the CCPSO solver.</p> <p>Parameters:</p> Name Type Description Default <code>problem</code> <code>Problem[List[float]]</code> <p>The constrained optimization problem.</p> required <code>swarm_size_x</code> <code>int</code> <p>The number of particles in the objective swarm.</p> <code>30</code> <code>swarm_size_l</code> <code>int</code> <p>The number of particles in the penalty swarm.</p> <code>30</code> <code>w</code> <code>float</code> <p>Inertia weight for both PSOs.</p> <code>0.729</code> <code>c1</code> <code>float</code> <p>Cognitive coefficient for both PSOs.</p> <code>2.05</code> <code>c2</code> <code>float</code> <p>Social coefficient for both PSOs.</p> <code>2.05</code> <code>lambda_bounds</code> <code>Tuple[float, float]</code> <p>The search space for Lagrangian                                  multipliers.</p> <code>(0.0, 1000.0)</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the base Solver class.</p> <code>{}</code> Source code in <code>cilpy/solver/ccpso.py</code> <pre><code>def __init__(\n    self,\n    problem: Problem[List[float]],\n    swarm_size_x: int = 30,\n    swarm_size_l: int = 30,\n    w: float = 0.729,\n    c1: float = 2.05,\n    c2: float = 2.05,\n    lambda_bounds: Tuple[float, float] = (0.0, 1000.0),\n    **kwargs: Any\n):\n    \"\"\"\n    Initializes the CCPSO solver.\n\n    Args:\n        problem (Problem[List[float]]): The constrained optimization problem.\n        swarm_size_x (int): The number of particles in the objective swarm.\n        swarm_size_l (int): The number of particles in the penalty swarm.\n        w (float): Inertia weight for both PSOs.\n        c1 (float): Cognitive coefficient for both PSOs.\n        c2 (float): Social coefficient for both PSOs.\n        lambda_bounds (Tuple[float, float]): The search space for Lagrangian\n                                             multipliers.\n        **kwargs: Additional arguments for the base Solver class.\n    \"\"\"\n    super().__init__(problem, **kwargs)\n\n    # PSO parameters\n    self.w = w\n    self.c1 = c1\n    self.c2 = c2\n    self.swarm_size_x = swarm_size_x\n    self.swarm_size_l = swarm_size_l\n\n    # Problem-specific information\n    self.objective = self.problem.get_objective_functions()[0]\n    self.inequality_constraints, self.equality_constraints = (\n        self.problem.get_constraint_functions()\n    )\n    self.lambda_dim = len(self.inequality_constraints) + len(\n        self.equality_constraints\n    )\n    self.lambda_bounds = lambda_bounds\n    self.is_dynamic, self.is_constrained_dynamic = self.problem.is_dynamic()\n\n    # --- Initialize Objective Swarm (P1 for x) ---\n    self.positions_x = [\n        self.problem.initialize_solution() for _ in range(self.swarm_size_x)\n    ]\n    self.velocities_x = [\n        self._initialize_velocity(self.problem.get_bounds())\n        for _ in range(self.swarm_size_x)\n    ]\n    self.pbest_positions_x = [p.copy() for p in self.positions_x]\n\n    # --- Initialize Penalty Swarm (P2 for \u03bc, \u03bb) ---\n    if self.lambda_dim &gt; 0:\n        self.positions_l = [\n            self._initialize_lambda_particle() for _ in range(self.swarm_size_l)\n        ]\n        l_lower_bounds = [self.lambda_bounds[0]] * self.lambda_dim\n        l_upper_bounds = [self.lambda_bounds[1]] * self.lambda_dim\n        self.bounds_l = (l_lower_bounds, l_upper_bounds)  # &lt;-- Note the 'self.'\n        self.velocities_l = [\n            self._initialize_velocity(self.bounds_l)\n            for _ in range(self.swarm_size_l)\n        ]  # &lt;-- Use self.bounds_l\n        self.pbest_positions_l = [p.copy() for p in self.positions_l]\n        # Initialize a placeholder gbest lambda for the first evaluation of swarm X\n        self.gbest_position_l = self._initialize_lambda_particle()\n    else:  # Unconstrained problem\n        self.positions_l, self.velocities_l, self.pbest_positions_l = [], [], []\n        self.gbest_position_l = []\n        self.bounds_l = ([], [])  # Initialize to avoid attribute errors\n\n    # --- Initial Evaluation and Best Finding ---\n    # Evaluate pbest_x using the initial placeholder gbest_l\n    self.pbest_values_x = [\n        self._calculate_lagrangian(pos, self.gbest_position_l)\n        for pos in self.pbest_positions_x\n    ]\n\n    # Find gbest_x based on initial evaluation\n    gbest_idx_x = min(\n        range(self.swarm_size_x), key=lambda i: self.pbest_values_x[i]\n    )\n    self.gbest_position_x = self.pbest_positions_x[gbest_idx_x]\n    self.gbest_value_x = self.pbest_values_x[gbest_idx_x]\n\n    if self.lambda_dim &gt; 0:\n        # Evaluate pbest_l using the newly found gbest_x\n        self.pbest_values_l = [\n            self._calculate_lagrangian(self.gbest_position_x, pos)\n            for pos in self.pbest_positions_l\n        ]\n\n        # Find gbest_l (maximization)\n        gbest_idx_l = max(\n            range(self.swarm_size_l), key=lambda i: self.pbest_values_l[i]\n        )\n        self.gbest_position_l = self.pbest_positions_l[gbest_idx_l]\n        self.gbest_value_l = self.pbest_values_l[gbest_idx_l]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.ccpso.CCPSO.get_best","title":"<code>get_best()</code>","text":"<p>Returns the best solution 'x' and its raw objective value (not the Lagrangian value).</p> Source code in <code>cilpy/solver/ccpso.py</code> <pre><code>def get_best(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"\n    Returns the best solution 'x' and its raw objective value (not the\n    Lagrangian value).\n    \"\"\"\n    # The user is interested in the objective function value of the best\n    # solution, not its Lagrangian fitness.\n    best_objective_value = self.objective(self.gbest_position_x)\n    return self.gbest_position_x, [best_objective_value]\n</code></pre>"},{"location":"api/solver/#cilpy.solver.ccpso.CCPSO.step","title":"<code>step()</code>","text":"<p>Performs one co-evolutionary iteration.</p> Source code in <code>cilpy/solver/ccpso.py</code> <pre><code>def step(self) -&gt; None:\n    \"\"\"Performs one co-evolutionary iteration.\"\"\"\n    if self.is_dynamic or self.is_constrained_dynamic:\n        # Re-evaluate all personal bests and global bests as fitness may have changed\n        self.pbest_values_x = [\n            self._calculate_lagrangian(pos, self.gbest_position_l)\n            for pos in self.pbest_positions_x\n        ]\n        self.gbest_value_x = self._calculate_lagrangian(\n            self.gbest_position_x, self.gbest_position_l\n        )\n\n        # Check if any other pbest_x is now better than the old gbest_x\n        current_best_idx_x = min(\n            range(self.swarm_size_x), key=lambda i: self.pbest_values_x[i]\n        )\n        if self.pbest_values_x[current_best_idx_x] &lt; self.gbest_value_x:\n            self.gbest_position_x = self.pbest_positions_x[current_best_idx_x]\n            self.gbest_value_x = self.pbest_values_x[current_best_idx_x]\n\n        if self.lambda_dim &gt; 0:\n            self.pbest_values_l = [\n                self._calculate_lagrangian(self.gbest_position_x, pos)\n                for pos in self.pbest_positions_l\n            ]\n            self.gbest_value_l = self._calculate_lagrangian(\n                self.gbest_position_x, self.gbest_position_l\n            )\n\n            # Check if any other pbest_l is now better than the old gbest_l (maximization)\n            current_best_idx_l = max(\n                range(self.swarm_size_l), key=lambda i: self.pbest_values_l[i]\n            )\n            if self.pbest_values_l[current_best_idx_l] &gt; self.gbest_value_l:\n                self.gbest_position_l = self.pbest_positions_l[current_best_idx_l]\n                self.gbest_value_l = self.pbest_values_l[current_best_idx_l]\n\n    # --- 1. Update Objective Swarm (P1) - Minimization ---\n    dim_x = self.problem.get_dimension()\n    bounds_x = self.problem.get_bounds()\n    for i in range(self.swarm_size_x):\n        # Update velocity\n        new_velocity = []\n        for d in range(dim_x):\n            r1, r2 = random.random(), random.random()\n            cognitive = (\n                self.c1\n                * r1\n                * (self.pbest_positions_x[i][d] - self.positions_x[i][d])\n            )\n            social = (\n                self.c2 * r2 * (self.gbest_position_x[d] - self.positions_x[i][d])\n            )\n            velocity = self.w * self.velocities_x[i][d] + cognitive + social\n            new_velocity.append(velocity)\n        self.velocities_x[i] = new_velocity\n\n        # Update position\n        new_position = [\n            pos + vel for pos, vel in zip(self.positions_x[i], self.velocities_x[i])\n        ]\n        self.positions_x[i] = self._clamp_position(new_position, bounds_x)\n\n        # Evaluate using gbest from penalty swarm\n        new_fitness = self._calculate_lagrangian(\n            self.positions_x[i], self.gbest_position_l\n        )\n\n        # Update personal best (minimization)\n        if new_fitness &lt; self.pbest_values_x[i]:\n            self.pbest_positions_x[i] = self.positions_x[i]\n            self.pbest_values_x[i] = new_fitness\n\n            # Update global best\n            if new_fitness &lt; self.gbest_value_x:\n                self.gbest_position_x = self.positions_x[i]\n                self.gbest_value_x = new_fitness\n\n    # --- 2. Update Penalty Swarm (P2) - Maximization ---\n    if self.lambda_dim &gt; 0:\n        for i in range(self.swarm_size_l):\n            # Update velocity\n            new_velocity = []\n            for d in range(self.lambda_dim):\n                r1, r2 = random.random(), random.random()\n                cognitive = (\n                    self.c1\n                    * r1\n                    * (self.pbest_positions_l[i][d] - self.positions_l[i][d])\n                )\n                social = (\n                    self.c2\n                    * r2\n                    * (self.gbest_position_l[d] - self.positions_l[i][d])\n                )\n                velocity = self.w * self.velocities_l[i][d] + cognitive + social\n                new_velocity.append(velocity)\n            self.velocities_l[i] = new_velocity\n\n            # Update position\n            new_position = [\n                pos + vel\n                for pos, vel in zip(self.positions_l[i], self.velocities_l[i])\n            ]\n            self.positions_l[i] = self._clamp_position(new_position, self.bounds_l)\n\n            # Evaluate using gbest from objective swarm\n            new_fitness = self._calculate_lagrangian(\n                self.gbest_position_x, self.positions_l[i]\n            )\n\n            # Update personal best (maximization)\n            if new_fitness &gt; self.pbest_values_l[i]:\n                self.pbest_positions_l[i] = self.positions_l[i]\n                self.pbest_values_l[i] = new_fitness\n\n                # Update global best\n                if new_fitness &gt; self.gbest_value_l:\n                    self.gbest_position_l = self.positions_l[i]\n                    self.gbest_value_l = new_fitness\n</code></pre>"},{"location":"guide/quick-start/","title":"Quick Start","text":"<p>The easiest way to see <code>cilpy</code> in action is to run one of the provided examples. This example runs a Particle Swarm Optimization (PSO) solver on the simple static Sphere function. Navigate to the examples directory and run the script: <pre><code>cd examples\npython sphere_pso.py\n</code></pre> You should see output like this: <pre><code>--- Starting Experiment: GbestPSO on Sphere ---\nSaving results to: output.csv\n  Iteration 50/500 complete. Current Best Fitness: 0.1234\n  Iteration 100/500 complete. Current Best Fitness: 0.0456\n  ...\nResults successfully saved.\n</code></pre> This will generate an *.out.csv file with the results of the run.</p>"}]}